"apiVersion": "v1"
"data":
  "kubernetes.alerting.rules.yaml": "\"groups\":\n- \"name\": \"kubernetes-apps\"\n  \"rules\":\n  - \"alert\": \"KubePodCrashLooping\"\n    \"annotations\":\n      \"description\": \"Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is in waiting state (reason: \\\"CrashLoopBackOff\\\").\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodcrashlooping\"\n      \"summary\": \"Pod is crash looping.\"\n    \"expr\": |\n      max_over_time(kube_pod_container_status_waiting_reason{reason=\"CrashLoopBackOff\", job=\"kube-state-metrics\"}[5m]) >= 1\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubePodNotReady\"\n    \"annotations\":\n      \"description\": \"Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than 15 minutes.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodnotready\"\n      \"summary\": \"Pod has been in a non-ready state for more than 15 minutes.\"\n    \"expr\": |\n      sum by (namespace, pod, cluster) (\n        max by(namespace, pod, cluster) (\n          kube_pod_status_phase{job=\"kube-state-metrics\", phase=~\"Pending|Unknown|Failed\"}\n        ) * on(namespace, pod, cluster) group_left(owner_kind) topk by(namespace, pod, cluster) (\n          1, max by(namespace, pod, owner_kind, cluster) (kube_pod_owner{owner_kind!=\"Job\"})\n        )\n      ) > 0\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeDeploymentGenerationMismatch\"\n    \"annotations\":\n      \"description\": \"Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment }} does not match, this indicates that the Deployment has failed but has not been rolled back.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentgenerationmismatch\"\n      \"summary\": \"Deployment generation mismatch due to possible roll-back\"\n    \"expr\": |\n      kube_deployment_status_observed_generation{job=\"kube-state-metrics\"}\n        !=\n      kube_deployment_metadata_generation{job=\"kube-state-metrics\"}\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeDeploymentReplicasMismatch\"\n    \"annotations\":\n      \"description\": \"Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected number of replicas for longer than 15 minutes.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentreplicasmismatch\"\n      \"summary\": \"Deployment has not matched the expected number of replicas.\"\n    \"expr\": |\n      (\n        kube_deployment_spec_replicas{job=\"kube-state-metrics\"}\n          >\n        kube_deployment_status_replicas_available{job=\"kube-state-metrics\"}\n      ) and (\n        changes(kube_deployment_status_replicas_updated{job=\"kube-state-metrics\"}[10m])\n          ==\n        0\n      )\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeDeploymentRolloutStuck\"\n    \"annotations\":\n      \"description\": \"Rollout of deployment {{ $labels.namespace }}/{{ $labels.deployment }} is not progressing for longer than 15 minutes.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentrolloutstuck\"\n      \"summary\": \"Deployment rollout is not progressing.\"\n    \"expr\": |\n      kube_deployment_status_condition{condition=\"Progressing\", status=\"false\",job=\"kube-state-metrics\"}\n      != 0\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeStatefulSetReplicasMismatch\"\n    \"annotations\":\n      \"description\": \"StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has not matched the expected number of replicas for longer than 15 minutes.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch\"\n      \"summary\": \"StatefulSet has not matched the expected number of replicas.\"\n    \"expr\": |\n      (\n        kube_statefulset_status_replicas_ready{job=\"kube-state-metrics\"}\n          !=\n        kube_statefulset_status_replicas{job=\"kube-state-metrics\"}\n      ) and (\n        changes(kube_statefulset_status_replicas_updated{job=\"kube-state-metrics\"}[10m])\n          ==\n        0\n      )\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeStatefulSetGenerationMismatch\"\n    \"annotations\":\n      \"description\": \"StatefulSet generation for {{ $labels.namespace }}/{{ $labels.statefulset }} does not match, this indicates that the StatefulSet has failed but has not been rolled back.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetgenerationmismatch\"\n      \"summary\": \"StatefulSet generation mismatch due to possible roll-back\"\n    \"expr\": |\n      kube_statefulset_status_observed_generation{job=\"kube-state-metrics\"}\n        !=\n      kube_statefulset_metadata_generation{job=\"kube-state-metrics\"}\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeStatefulSetUpdateNotRolledOut\"\n    \"annotations\":\n      \"description\": \"StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update has not been rolled out.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetupdatenotrolledout\"\n      \"summary\": \"StatefulSet update has not been rolled out.\"\n    \"expr\": |\n      (\n        max by(namespace, statefulset, job, cluster) (\n          kube_statefulset_status_current_revision{job=\"kube-state-metrics\"}\n            unless\n          kube_statefulset_status_update_revision{job=\"kube-state-metrics\"}\n        )\n          *\n        (\n          kube_statefulset_replicas{job=\"kube-state-metrics\"}\n            !=\n          kube_statefulset_status_replicas_updated{job=\"kube-state-metrics\"}\n        )\n      )  and (\n        changes(kube_statefulset_status_replicas_updated{job=\"kube-state-metrics\"}[5m])\n          ==\n        0\n      )\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeDaemonSetRolloutStuck\"\n    \"annotations\":\n      \"description\": \"DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} has not finished or progressed for at least 15m.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetrolloutstuck\"\n      \"summary\": \"DaemonSet rollout is stuck.\"\n    \"expr\": |\n      (\n        (\n          kube_daemonset_status_current_number_scheduled{job=\"kube-state-metrics\"}\n           !=\n          kube_daemonset_status_desired_number_scheduled{job=\"kube-state-metrics\"}\n        ) or (\n          kube_daemonset_status_number_misscheduled{job=\"kube-state-metrics\"}\n           !=\n          0\n        ) or (\n          kube_daemonset_status_updated_number_scheduled{job=\"kube-state-metrics\"}\n           !=\n          kube_daemonset_status_desired_number_scheduled{job=\"kube-state-metrics\"}\n        ) or (\n          kube_daemonset_status_number_available{job=\"kube-state-metrics\"}\n           !=\n          kube_daemonset_status_desired_number_scheduled{job=\"kube-state-metrics\"}\n        )\n      ) and (\n        changes(kube_daemonset_status_updated_number_scheduled{job=\"kube-state-metrics\"}[5m])\n          ==\n        0\n      )\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeContainerWaiting\"\n    \"annotations\":\n      \"description\": \"pod/{{ $labels.pod }} in namespace {{ $labels.namespace }} on container {{ $labels.container}} has been in waiting state for longer than 1 hour. (reason: \\\"{{ $labels.reason }}\\\").\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecontainerwaiting\"\n      \"summary\": \"Pod container waiting longer than 1 hour\"\n    \"expr\": |\n      kube_pod_container_status_waiting_reason{reason!=\"CrashLoopBackOff\", job=\"kube-state-metrics\"} > 0\n    \"for\": \"1h\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeDaemonSetNotScheduled\"\n    \"annotations\":\n      \"description\": \"{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are not scheduled.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetnotscheduled\"\n      \"summary\": \"DaemonSet pods are not scheduled.\"\n    \"expr\": |\n      kube_daemonset_status_desired_number_scheduled{job=\"kube-state-metrics\"}\n        -\n      kube_daemonset_status_current_number_scheduled{job=\"kube-state-metrics\"} > 0\n    \"for\": \"10m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeDaemonSetMisScheduled\"\n    \"annotations\":\n      \"description\": \"{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are running where they are not supposed to run.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetmisscheduled\"\n      \"summary\": \"DaemonSet pods are misscheduled.\"\n    \"expr\": |\n      kube_daemonset_status_number_misscheduled{job=\"kube-state-metrics\"} > 0\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeJobNotCompleted\"\n    \"annotations\":\n      \"description\": \"Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more than {{ \\\"43200\\\" | humanizeDuration }} to complete.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobnotcompleted\"\n      \"summary\": \"Job did not complete in time\"\n    \"expr\": |\n      time() - max by(namespace, job_name, cluster) (kube_job_status_start_time{job=\"kube-state-metrics\"}\n        and\n      kube_job_status_active{job=\"kube-state-metrics\"} > 0) > 43200\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeJobFailed\"\n    \"annotations\":\n      \"description\": \"Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete. Removing failed job after investigation should clear this alert.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobfailed\"\n      \"summary\": \"Job failed to complete.\"\n    \"expr\": |\n      kube_job_failed{job=\"kube-state-metrics\"}  > 0\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeHpaReplicasMismatch\"\n    \"annotations\":\n      \"description\": \"HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler  }} has not matched the desired number of replicas for longer than 15 minutes.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubehpareplicasmismatch\"\n      \"summary\": \"HPA has not matched desired number of replicas.\"\n    \"expr\": |\n      (kube_horizontalpodautoscaler_status_desired_replicas{job=\"kube-state-metrics\"}\n        !=\n      kube_horizontalpodautoscaler_status_current_replicas{job=\"kube-state-metrics\"})\n        and\n      (kube_horizontalpodautoscaler_status_current_replicas{job=\"kube-state-metrics\"}\n        >\n      kube_horizontalpodautoscaler_spec_min_replicas{job=\"kube-state-metrics\"})\n        and\n      (kube_horizontalpodautoscaler_status_current_replicas{job=\"kube-state-metrics\"}\n        <\n      kube_horizontalpodautoscaler_spec_max_replicas{job=\"kube-state-metrics\"})\n        and\n      changes(kube_horizontalpodautoscaler_status_current_replicas{job=\"kube-state-metrics\"}[15m]) == 0\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeHpaMaxedOut\"\n    \"annotations\":\n      \"description\": \"HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler  }} has been running at max replicas for longer than 15 minutes.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubehpamaxedout\"\n      \"summary\": \"HPA is running at max replicas\"\n    \"expr\": |\n      kube_horizontalpodautoscaler_status_current_replicas{job=\"kube-state-metrics\"}\n        ==\n      kube_horizontalpodautoscaler_spec_max_replicas{job=\"kube-state-metrics\"}\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n- \"name\": \"kubernetes-resources\"\n  \"rules\":\n  - \"alert\": \"KubeCPUOvercommit\"\n    \"annotations\":\n      \"description\": \"Cluster has overcommitted CPU resource requests for Pods by {{ $value }} CPU shares and cannot tolerate node failure.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuovercommit\"\n      \"summary\": \"Cluster has overcommitted CPU resource requests.\"\n    \"expr\": |\n      sum(namespace_cpu:kube_pod_container_resource_requests:sum{}) - (sum(kube_node_status_allocatable{resource=\"cpu\", job=\"kube-state-metrics\"}) - max(kube_node_status_allocatable{resource=\"cpu\", job=\"kube-state-metrics\"})) > 0\n      and\n      (sum(kube_node_status_allocatable{resource=\"cpu\", job=\"kube-state-metrics\"}) - max(kube_node_status_allocatable{resource=\"cpu\", job=\"kube-state-metrics\"})) > 0\n    \"for\": \"10m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeMemoryOvercommit\"\n    \"annotations\":\n      \"description\": \"Cluster has overcommitted memory resource requests for Pods by {{ $value | humanize }} bytes and cannot tolerate node failure.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememoryovercommit\"\n      \"summary\": \"Cluster has overcommitted memory resource requests.\"\n    \"expr\": |\n      sum(namespace_memory:kube_pod_container_resource_requests:sum{}) - (sum(kube_node_status_allocatable{resource=\"memory\", job=\"kube-state-metrics\"}) - max(kube_node_status_allocatable{resource=\"memory\", job=\"kube-state-metrics\"})) > 0\n      and\n      (sum(kube_node_status_allocatable{resource=\"memory\", job=\"kube-state-metrics\"}) - max(kube_node_status_allocatable{resource=\"memory\", job=\"kube-state-metrics\"})) > 0\n    \"for\": \"10m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeCPUQuotaOvercommit\"\n    \"annotations\":\n      \"description\": \"Cluster has overcommitted CPU resource requests for Namespaces.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuquotaovercommit\"\n      \"summary\": \"Cluster has overcommitted CPU resource requests.\"\n    \"expr\": |\n      sum(min without(resource) (kube_resourcequota{job=\"kube-state-metrics\", type=\"hard\", resource=~\"(cpu|requests.cpu)\"}))\n        /\n      sum(kube_node_status_allocatable{resource=\"cpu\", job=\"kube-state-metrics\"})\n        > 1.5\n    \"for\": \"5m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeMemoryQuotaOvercommit\"\n    \"annotations\":\n      \"description\": \"Cluster has overcommitted memory resource requests for Namespaces.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememoryquotaovercommit\"\n      \"summary\": \"Cluster has overcommitted memory resource requests.\"\n    \"expr\": |\n      sum(min without(resource) (kube_resourcequota{job=\"kube-state-metrics\", type=\"hard\", resource=~\"(memory|requests.memory)\"}))\n        /\n      sum(kube_node_status_allocatable{resource=\"memory\", job=\"kube-state-metrics\"})\n        > 1.5\n    \"for\": \"5m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeQuotaAlmostFull\"\n    \"annotations\":\n      \"description\": \"Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotaalmostfull\"\n      \"summary\": \"Namespace quota is going to be full.\"\n    \"expr\": |\n      kube_resourcequota{job=\"kube-state-metrics\", type=\"used\"}\n        / ignoring(instance, job, type)\n      (kube_resourcequota{job=\"kube-state-metrics\", type=\"hard\"} > 0)\n        > 0.9 < 1\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"info\"\n  - \"alert\": \"KubeQuotaFullyUsed\"\n    \"annotations\":\n      \"description\": \"Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotafullyused\"\n      \"summary\": \"Namespace quota is fully used.\"\n    \"expr\": |\n      kube_resourcequota{job=\"kube-state-metrics\", type=\"used\"}\n        / ignoring(instance, job, type)\n      (kube_resourcequota{job=\"kube-state-metrics\", type=\"hard\"} > 0)\n        == 1\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"info\"\n  - \"alert\": \"KubeQuotaExceeded\"\n    \"annotations\":\n      \"description\": \"Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotaexceeded\"\n      \"summary\": \"Namespace quota has exceeded the limits.\"\n    \"expr\": |\n      kube_resourcequota{job=\"kube-state-metrics\", type=\"used\"}\n        / ignoring(instance, job, type)\n      (kube_resourcequota{job=\"kube-state-metrics\", type=\"hard\"} > 0)\n        > 1\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"CPUThrottlingHigh\"\n    \"annotations\":\n      \"description\": \"{{ $value | humanizePercentage }} throttling of CPU in namespace {{ $labels.namespace }} for container {{ $labels.container }} in pod {{ $labels.pod }}.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-cputhrottlinghigh\"\n      \"summary\": \"Processes experience elevated CPU throttling.\"\n    \"expr\": |\n      sum(increase(container_cpu_cfs_throttled_periods_total{container!=\"\", job=\"cadvisor\", }[5m])) without (id, metrics_path, name, image, endpoint, job, node)\n        /\n      sum(increase(container_cpu_cfs_periods_total{job=\"cadvisor\", }[5m])) without (id, metrics_path, name, image, endpoint, job, node)\n        > ( 25 / 100 )\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"info\"\n- \"name\": \"kubernetes-storage\"\n  \"rules\":\n  - \"alert\": \"KubePersistentVolumeFillingUp\"\n    \"annotations\":\n      \"description\": \"The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} is only {{ $value | humanizePercentage }} free.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumefillingup\"\n      \"summary\": \"PersistentVolume is filling up.\"\n    \"expr\": |\n      (\n        kubelet_volume_stats_available_bytes{job=\"kubelet\"}\n          /\n        kubelet_volume_stats_capacity_bytes{job=\"kubelet\"}\n      ) < 0.03\n      and\n      kubelet_volume_stats_used_bytes{job=\"kubelet\"} > 0\n      unless on(cluster, namespace, persistentvolumeclaim)\n      kube_persistentvolumeclaim_access_mode{ access_mode=\"ReadOnlyMany\"} == 1\n      unless on(cluster, namespace, persistentvolumeclaim)\n      kube_persistentvolumeclaim_labels{label_excluded_from_alerts=\"true\"} == 1\n    \"for\": \"1m\"\n    \"labels\":\n      \"severity\": \"critical\"\n  - \"alert\": \"KubePersistentVolumeFillingUp\"\n    \"annotations\":\n      \"description\": \"Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} is expected to fill up within four days. Currently {{ $value | humanizePercentage }} is available.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumefillingup\"\n      \"summary\": \"PersistentVolume is filling up.\"\n    \"expr\": |\n      (\n        kubelet_volume_stats_available_bytes{job=\"kubelet\"}\n          /\n        kubelet_volume_stats_capacity_bytes{job=\"kubelet\"}\n      ) < 0.15\n      and\n      kubelet_volume_stats_used_bytes{job=\"kubelet\"} > 0\n      and\n      predict_linear(kubelet_volume_stats_available_bytes{job=\"kubelet\"}[6h], 4 * 24 * 3600) < 0\n      unless on(cluster, namespace, persistentvolumeclaim)\n      kube_persistentvolumeclaim_access_mode{ access_mode=\"ReadOnlyMany\"} == 1\n      unless on(cluster, namespace, persistentvolumeclaim)\n      kube_persistentvolumeclaim_labels{label_excluded_from_alerts=\"true\"} == 1\n    \"for\": \"1h\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubePersistentVolumeInodesFillingUp\"\n    \"annotations\":\n      \"description\": \"The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} only has {{ $value | humanizePercentage }} free inodes.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumeinodesfillingup\"\n      \"summary\": \"PersistentVolumeInodes are filling up.\"\n    \"expr\": |\n      (\n        kubelet_volume_stats_inodes_free{job=\"kubelet\"}\n          /\n        kubelet_volume_stats_inodes{job=\"kubelet\"}\n      ) < 0.03\n      and\n      kubelet_volume_stats_inodes_used{job=\"kubelet\"} > 0\n      unless on(cluster, namespace, persistentvolumeclaim)\n      kube_persistentvolumeclaim_access_mode{ access_mode=\"ReadOnlyMany\"} == 1\n      unless on(cluster, namespace, persistentvolumeclaim)\n      kube_persistentvolumeclaim_labels{label_excluded_from_alerts=\"true\"} == 1\n    \"for\": \"1m\"\n    \"labels\":\n      \"severity\": \"critical\"\n  - \"alert\": \"KubePersistentVolumeInodesFillingUp\"\n    \"annotations\":\n      \"description\": \"Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} is expected to run out of inodes within four days. Currently {{ $value | humanizePercentage }} of its inodes are free.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumeinodesfillingup\"\n      \"summary\": \"PersistentVolumeInodes are filling up.\"\n    \"expr\": |\n      (\n        kubelet_volume_stats_inodes_free{job=\"kubelet\"}\n          /\n        kubelet_volume_stats_inodes{job=\"kubelet\"}\n      ) < 0.15\n      and\n      kubelet_volume_stats_inodes_used{job=\"kubelet\"} > 0\n      and\n      predict_linear(kubelet_volume_stats_inodes_free{job=\"kubelet\"}[6h], 4 * 24 * 3600) < 0\n      unless on(cluster, namespace, persistentvolumeclaim)\n      kube_persistentvolumeclaim_access_mode{ access_mode=\"ReadOnlyMany\"} == 1\n      unless on(cluster, namespace, persistentvolumeclaim)\n      kube_persistentvolumeclaim_labels{label_excluded_from_alerts=\"true\"} == 1\n    \"for\": \"1h\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubePersistentVolumeErrors\"\n    \"annotations\":\n      \"description\": \"The persistent volume {{ $labels.persistentvolume }} {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} has status {{ $labels.phase }}.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumeerrors\"\n      \"summary\": \"PersistentVolume is having issues with provisioning.\"\n    \"expr\": |\n      kube_persistentvolume_status_phase{phase=~\"Failed|Pending\",job=\"kube-state-metrics\"} > 0\n    \"for\": \"5m\"\n    \"labels\":\n      \"severity\": \"critical\"\n- \"name\": \"kubernetes-system\"\n  \"rules\":\n  - \"alert\": \"KubeVersionMismatch\"\n    \"annotations\":\n      \"description\": \"There are {{ $value }} different semantic versions of Kubernetes components running.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeversionmismatch\"\n      \"summary\": \"Different semantic versions of Kubernetes components running.\"\n    \"expr\": |\n      count by (cluster) (count by (git_version, cluster) (label_replace(kubernetes_build_info{job!~\"kube-dns|coredns\"},\"git_version\",\"$1\",\"git_version\",\"(v[0-9]*.[0-9]*).*\"))) > 1\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeClientErrors\"\n    \"annotations\":\n      \"description\": \"Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance }}' is experiencing {{ $value | humanizePercentage }} errors.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclienterrors\"\n      \"summary\": \"Kubernetes API server client is experiencing errors.\"\n    \"expr\": |\n      (sum(rate(rest_client_requests_total{job=\"kube-apiserver\",code=~\"5..\"}[5m])) by (cluster, instance, job, namespace)\n        /\n      sum(rate(rest_client_requests_total{job=\"kube-apiserver\"}[5m])) by (cluster, instance, job, namespace))\n      > 0.01\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n- \"name\": \"kube-apiserver-slos\"\n  \"rules\":\n  - \"alert\": \"KubeAPIErrorBudgetBurn\"\n    \"annotations\":\n      \"description\": \"The API server is burning too much error budget.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorbudgetburn\"\n      \"summary\": \"The API server is burning too much error budget.\"\n    \"expr\": |\n      sum by(cluster) (apiserver_request:burnrate1h) > (14.40 * 0.01000)\n      and on(cluster)\n      sum by(cluster) (apiserver_request:burnrate5m) > (14.40 * 0.01000)\n    \"for\": \"2m\"\n    \"labels\":\n      \"long\": \"1h\"\n      \"severity\": \"critical\"\n      \"short\": \"5m\"\n  - \"alert\": \"KubeAPIErrorBudgetBurn\"\n    \"annotations\":\n      \"description\": \"The API server is burning too much error budget.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorbudgetburn\"\n      \"summary\": \"The API server is burning too much error budget.\"\n    \"expr\": |\n      sum by(cluster) (apiserver_request:burnrate6h) > (6.00 * 0.01000)\n      and on(cluster)\n      sum by(cluster) (apiserver_request:burnrate30m) > (6.00 * 0.01000)\n    \"for\": \"15m\"\n    \"labels\":\n      \"long\": \"6h\"\n      \"severity\": \"critical\"\n      \"short\": \"30m\"\n  - \"alert\": \"KubeAPIErrorBudgetBurn\"\n    \"annotations\":\n      \"description\": \"The API server is burning too much error budget.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorbudgetburn\"\n      \"summary\": \"The API server is burning too much error budget.\"\n    \"expr\": |\n      sum by(cluster) (apiserver_request:burnrate1d) > (3.00 * 0.01000)\n      and on(cluster)\n      sum by(cluster) (apiserver_request:burnrate2h) > (3.00 * 0.01000)\n    \"for\": \"1h\"\n    \"labels\":\n      \"long\": \"1d\"\n      \"severity\": \"warning\"\n      \"short\": \"2h\"\n  - \"alert\": \"KubeAPIErrorBudgetBurn\"\n    \"annotations\":\n      \"description\": \"The API server is burning too much error budget.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorbudgetburn\"\n      \"summary\": \"The API server is burning too much error budget.\"\n    \"expr\": |\n      sum by(cluster) (apiserver_request:burnrate3d) > (1.00 * 0.01000)\n      and on(cluster)\n      sum by(cluster) (apiserver_request:burnrate6h) > (1.00 * 0.01000)\n    \"for\": \"3h\"\n    \"labels\":\n      \"long\": \"3d\"\n      \"severity\": \"warning\"\n      \"short\": \"6h\"\n- \"name\": \"kubernetes-system-apiserver\"\n  \"rules\":\n  - \"alert\": \"KubeClientCertificateExpiration\"\n    \"annotations\":\n      \"description\": \"A client certificate used to authenticate to kubernetes apiserver is expiring in less than 7.0 days.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration\"\n      \"summary\": \"Client certificate is about to expire.\"\n    \"expr\": |\n      histogram_quantile(0.01, sum without (namespace, service, endpoint) (rate(apiserver_client_certificate_expiration_seconds_bucket{job=\"kube-apiserver\"}[5m]))) < 604800\n      and\n      on(job, cluster, instance) apiserver_client_certificate_expiration_seconds_count{job=\"kube-apiserver\"} > 0\n    \"for\": \"5m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeClientCertificateExpiration\"\n    \"annotations\":\n      \"description\": \"A client certificate used to authenticate to kubernetes apiserver is expiring in less than 24.0 hours.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration\"\n      \"summary\": \"Client certificate is about to expire.\"\n    \"expr\": |\n      histogram_quantile(0.01, sum without (namespace, service, endpoint) (rate(apiserver_client_certificate_expiration_seconds_bucket{job=\"kube-apiserver\"}[5m]))) < 86400\n      and\n      on(job, cluster, instance) apiserver_client_certificate_expiration_seconds_count{job=\"kube-apiserver\"} > 0\n    \"for\": \"5m\"\n    \"labels\":\n      \"severity\": \"critical\"\n  - \"alert\": \"KubeAggregatedAPIErrors\"\n    \"annotations\":\n      \"description\": \"Kubernetes aggregated API {{ $labels.instance }}/{{ $labels.name }} has reported {{ $labels.reason }} errors.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeaggregatedapierrors\"\n      \"summary\": \"Kubernetes aggregated API has reported errors.\"\n    \"expr\": |\n      sum by(cluster, instance, name, reason)(increase(aggregator_unavailable_apiservice_total{job=\"kube-apiserver\"}[1m])) > 0\n    \"for\": \"10m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeAggregatedAPIDown\"\n    \"annotations\":\n      \"description\": \"Kubernetes aggregated API {{ $labels.name }}/{{ $labels.namespace }} has been only {{ $value | humanize }}% available over the last 10m.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeaggregatedapidown\"\n      \"summary\": \"Kubernetes aggregated API is down.\"\n    \"expr\": |\n      (1 - max by(name, namespace, cluster)(avg_over_time(aggregator_unavailable_apiservice{job=\"kube-apiserver\"}[10m]))) * 100 < 85\n    \"for\": \"5m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeAPIDown\"\n    \"annotations\":\n      \"description\": \"KubeAPI has disappeared from Prometheus target discovery.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapidown\"\n      \"summary\": \"Target disappeared from Prometheus target discovery.\"\n    \"expr\": |\n      absent(up{job=\"kube-apiserver\"} == 1)\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"critical\"\n  - \"alert\": \"KubeAPITerminatedRequests\"\n    \"annotations\":\n      \"description\": \"The kubernetes apiserver has terminated {{ $value | humanizePercentage }} of its incoming requests.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapiterminatedrequests\"\n      \"summary\": \"The kubernetes apiserver has terminated {{ $value | humanizePercentage }} of its incoming requests.\"\n    \"expr\": |\n      sum by(cluster) (rate(apiserver_request_terminations_total{job=\"kube-apiserver\"}[10m])) / ( sum by(cluster) (rate(apiserver_request_total{job=\"kube-apiserver\"}[10m])) + sum by(cluster) (rate(apiserver_request_terminations_total{job=\"kube-apiserver\"}[10m])) ) > 0.20\n    \"for\": \"5m\"\n    \"labels\":\n      \"severity\": \"warning\"\n- \"name\": \"kubernetes-system-kubelet\"\n  \"rules\":\n  - \"alert\": \"KubeNodeNotReady\"\n    \"annotations\":\n      \"description\": \"{{ $labels.node }} has been unready for more than 15 minutes.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodenotready\"\n      \"summary\": \"Node is not ready.\"\n    \"expr\": |\n      kube_node_status_condition{job=\"kube-state-metrics\",condition=\"Ready\",status=\"true\"} == 0\n      and on (cluster, node)\n      kube_node_spec_unschedulable{job=\"kube-state-metrics\"} == 0\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeNodeUnreachable\"\n    \"annotations\":\n      \"description\": \"{{ $labels.node }} is unreachable and some workloads may be rescheduled.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodeunreachable\"\n      \"summary\": \"Node is unreachable.\"\n    \"expr\": |\n      (kube_node_spec_taint{job=\"kube-state-metrics\",key=\"node.kubernetes.io/unreachable\",effect=\"NoSchedule\"} unless ignoring(key,value) kube_node_spec_taint{job=\"kube-state-metrics\",key=~\"ToBeDeletedByClusterAutoscaler|cloud.google.com/impending-node-termination|aws-node-termination-handler/spot-itn\"}) == 1\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeletTooManyPods\"\n    \"annotations\":\n      \"description\": \"Kubelet '{{ $labels.node }}' is running at {{ $value | humanizePercentage }} of its Pod capacity.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubelettoomanypods\"\n      \"summary\": \"Kubelet is running at capacity.\"\n    \"expr\": |\n      (\n        max by (cluster, instance) (\n          kubelet_running_pods{job=\"kubelet\"} > 1\n        )\n        * on (cluster, instance) group_left(node)\n        max by (cluster, instance, node) (\n          kubelet_node_name{job=\"kubelet\"}\n        )\n      )\n      / on (cluster, node) group_left()\n      max by (cluster, node) (\n        kube_node_status_capacity{job=\"kube-state-metrics\", resource=\"pods\"} != 1\n      ) > 0.95\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"info\"\n  - \"alert\": \"KubeNodeReadinessFlapping\"\n    \"annotations\":\n      \"description\": \"The readiness status of node {{ $labels.node }} has changed {{ $value }} times in the last 15 minutes.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodereadinessflapping\"\n      \"summary\": \"Node readiness status is flapping.\"\n    \"expr\": |\n      sum(changes(kube_node_status_condition{job=\"kube-state-metrics\",status=\"true\",condition=\"Ready\"}[15m])) by (cluster, node) > 2\n      and on (cluster, node)\n      kube_node_spec_unschedulable{job=\"kube-state-metrics\"} == 0\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeletPlegDurationHigh\"\n    \"annotations\":\n      \"description\": \"The Kubelet Pod Lifecycle Event Generator has a 99th percentile duration of {{ $value }} seconds on node {{ $labels.node }}.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletplegdurationhigh\"\n      \"summary\": \"Kubelet Pod Lifecycle Event Generator is taking too long to relist.\"\n    \"expr\": |\n      node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile{quantile=\"0.99\"} >= 10\n    \"for\": \"5m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeletPodStartUpLatencyHigh\"\n    \"annotations\":\n      \"description\": \"Kubelet Pod startup 99th percentile latency is {{ $value }} seconds on node {{ $labels.node }}.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletpodstartuplatencyhigh\"\n      \"summary\": \"Kubelet Pod startup latency is too high.\"\n    \"expr\": |\n      histogram_quantile(0.99, sum(rate(kubelet_pod_worker_duration_seconds_bucket{job=\"kubelet\"}[5m])) by (cluster, instance, le)) * on(cluster, instance) group_left(node) kubelet_node_name{job=\"kubelet\"} > 60\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeletClientCertificateExpiration\"\n    \"annotations\":\n      \"description\": \"Client certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletclientcertificateexpiration\"\n      \"summary\": \"Kubelet client certificate is about to expire.\"\n    \"expr\": |\n      kubelet_certificate_manager_client_ttl_seconds < 604800\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeletClientCertificateExpiration\"\n    \"annotations\":\n      \"description\": \"Client certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletclientcertificateexpiration\"\n      \"summary\": \"Kubelet client certificate is about to expire.\"\n    \"expr\": |\n      kubelet_certificate_manager_client_ttl_seconds < 86400\n    \"labels\":\n      \"severity\": \"critical\"\n  - \"alert\": \"KubeletServerCertificateExpiration\"\n    \"annotations\":\n      \"description\": \"Server certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletservercertificateexpiration\"\n      \"summary\": \"Kubelet server certificate is about to expire.\"\n    \"expr\": |\n      kubelet_certificate_manager_server_ttl_seconds < 604800\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeletServerCertificateExpiration\"\n    \"annotations\":\n      \"description\": \"Server certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletservercertificateexpiration\"\n      \"summary\": \"Kubelet server certificate is about to expire.\"\n    \"expr\": |\n      kubelet_certificate_manager_server_ttl_seconds < 86400\n    \"labels\":\n      \"severity\": \"critical\"\n  - \"alert\": \"KubeletClientCertificateRenewalErrors\"\n    \"annotations\":\n      \"description\": \"Kubelet on node {{ $labels.node }} has failed to renew its client certificate ({{ $value | humanize }} errors in the last 5 minutes).\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletclientcertificaterenewalerrors\"\n      \"summary\": \"Kubelet has failed to renew its client certificate.\"\n    \"expr\": |\n      increase(kubelet_certificate_manager_client_expiration_renew_errors[5m]) > 0\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeletServerCertificateRenewalErrors\"\n    \"annotations\":\n      \"description\": \"Kubelet on node {{ $labels.node }} has failed to renew its server certificate ({{ $value | humanize }} errors in the last 5 minutes).\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletservercertificaterenewalerrors\"\n      \"summary\": \"Kubelet has failed to renew its server certificate.\"\n    \"expr\": |\n      increase(kubelet_server_expiration_renew_errors[5m]) > 0\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"KubeletDown\"\n    \"annotations\":\n      \"description\": \"Kubelet has disappeared from Prometheus target discovery.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletdown\"\n      \"summary\": \"Target disappeared from Prometheus target discovery.\"\n    \"expr\": |\n      absent(up{job=\"kubelet\"} == 1)\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"critical\"\n- \"name\": \"kubernetes-system-scheduler\"\n  \"rules\":\n  - \"alert\": \"KubeSchedulerDown\"\n    \"annotations\":\n      \"description\": \"KubeScheduler has disappeared from Prometheus target discovery.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeschedulerdown\"\n      \"summary\": \"Target disappeared from Prometheus target discovery.\"\n    \"expr\": |\n      absent(up{job=\"kube-scheduler\"} == 1)\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"critical\"\n- \"name\": \"kubernetes-system-controller-manager\"\n  \"rules\":\n  - \"alert\": \"KubeControllerManagerDown\"\n    \"annotations\":\n      \"description\": \"KubeControllerManager has disappeared from Prometheus target discovery.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecontrollermanagerdown\"\n      \"summary\": \"Target disappeared from Prometheus target discovery.\"\n    \"expr\": |\n      absent(up{job=\"kube-controller-manager\"} == 1)\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"critical\"\n- \"name\": \"kubernetes-system-kube-proxy\"\n  \"rules\":\n  - \"alert\": \"KubeProxyDown\"\n    \"annotations\":\n      \"description\": \"KubeProxy has disappeared from Prometheus target discovery.\"\n      \"runbook_url\": \"https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeproxydown\"\n      \"summary\": \"Target disappeared from Prometheus target discovery.\"\n    \"expr\": |\n      absent(up{job=\"kube-proxy\"} == 1)\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"critical\""
  "kubernetes.recording.rules.yaml": "\"groups\":\n- \"interval\": \"3m\"\n  \"name\": \"kube-apiserver-availability.rules\"\n  \"rules\":\n  - \"expr\": |\n      avg_over_time(code_verb:apiserver_request_total:increase1h[30d]) * 24 * 30\n    \"record\": \"code_verb:apiserver_request_total:increase30d\"\n  - \"expr\": |\n      sum by (cluster, code) (code_verb:apiserver_request_total:increase30d{verb=~\"LIST|GET\"})\n    \"labels\":\n      \"verb\": \"read\"\n    \"record\": \"code:apiserver_request_total:increase30d\"\n  - \"expr\": |\n      sum by (cluster, code) (code_verb:apiserver_request_total:increase30d{verb=~\"POST|PUT|PATCH|DELETE\"})\n    \"labels\":\n      \"verb\": \"write\"\n    \"record\": \"code:apiserver_request_total:increase30d\"\n  - \"expr\": |\n      sum by (cluster, verb, scope, le) (increase(apiserver_request_sli_duration_seconds_bucket[1h]))\n    \"record\": \"cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase1h\"\n  - \"expr\": |\n      sum by (cluster, verb, scope, le) (avg_over_time(cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase1h[30d]) * 24 * 30)\n    \"record\": \"cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d\"\n  - \"expr\": |\n      sum by (cluster, verb, scope) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase1h{le=\"+Inf\"})\n    \"record\": \"cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase1h\"\n  - \"expr\": |\n      sum by (cluster, verb, scope) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{le=\"+Inf\"})\n    \"record\": \"cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase30d\"\n  - \"expr\": |\n      1 - (\n        (\n          # write too slow\n          sum by (cluster) (cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase30d{verb=~\"POST|PUT|PATCH|DELETE\"})\n          -\n          sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~\"POST|PUT|PATCH|DELETE\",le=~\"1(\\\\.0)?\"})\n        ) +\n        (\n          # read too slow\n          sum by (cluster) (cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase30d{verb=~\"LIST|GET\"})\n          -\n          (\n            (\n              sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~\"LIST|GET\",scope=~\"resource|\",le=~\"1(\\\\.0)?\"})\n              or\n              vector(0)\n            )\n            +\n            sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~\"LIST|GET\",scope=\"namespace\",le=~\"5(\\\\.0)?\"})\n            +\n            sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~\"LIST|GET\",scope=\"cluster\",le=~\"30(\\\\.0)?\"})\n          )\n        ) +\n        # errors\n        sum by (cluster) (code:apiserver_request_total:increase30d{code=~\"5..\"} or vector(0))\n      )\n      /\n      sum by (cluster) (code:apiserver_request_total:increase30d)\n    \"labels\":\n      \"verb\": \"all\"\n    \"record\": \"apiserver_request:availability30d\"\n  - \"expr\": |\n      1 - (\n        sum by (cluster) (cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase30d{verb=~\"LIST|GET\"})\n        -\n        (\n          # too slow\n          (\n            sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~\"LIST|GET\",scope=~\"resource|\",le=~\"1(\\\\.0)?\"})\n            or\n            vector(0)\n          )\n          +\n          sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~\"LIST|GET\",scope=\"namespace\",le=~\"5(\\\\.0)?\"})\n          +\n          sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~\"LIST|GET\",scope=\"cluster\",le=~\"30(\\\\.0)?\"})\n        )\n        +\n        # errors\n        sum by (cluster) (code:apiserver_request_total:increase30d{verb=\"read\",code=~\"5..\"} or vector(0))\n      )\n      /\n      sum by (cluster) (code:apiserver_request_total:increase30d{verb=\"read\"})\n    \"labels\":\n      \"verb\": \"read\"\n    \"record\": \"apiserver_request:availability30d\"\n  - \"expr\": |\n      1 - (\n        (\n          # too slow\n          sum by (cluster) (cluster_verb_scope:apiserver_request_sli_duration_seconds_count:increase30d{verb=~\"POST|PUT|PATCH|DELETE\"})\n          -\n          sum by (cluster) (cluster_verb_scope_le:apiserver_request_sli_duration_seconds_bucket:increase30d{verb=~\"POST|PUT|PATCH|DELETE\",le=~\"1(\\\\.0)?\"})\n        )\n        +\n        # errors\n        sum by (cluster) (code:apiserver_request_total:increase30d{verb=\"write\",code=~\"5..\"} or vector(0))\n      )\n      /\n      sum by (cluster) (code:apiserver_request_total:increase30d{verb=\"write\"})\n    \"labels\":\n      \"verb\": \"write\"\n    \"record\": \"apiserver_request:availability30d\"\n  - \"expr\": |\n      sum by (cluster,code,resource) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET\"}[5m]))\n    \"labels\":\n      \"verb\": \"read\"\n    \"record\": \"code_resource:apiserver_request_total:rate5m\"\n  - \"expr\": |\n      sum by (cluster,code,resource) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\"}[5m]))\n    \"labels\":\n      \"verb\": \"write\"\n    \"record\": \"code_resource:apiserver_request_total:rate5m\"\n  - \"expr\": |\n      sum by (cluster, code, verb) (increase(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET|POST|PUT|PATCH|DELETE\",code=~\"2..\"}[1h]))\n    \"record\": \"code_verb:apiserver_request_total:increase1h\"\n  - \"expr\": |\n      sum by (cluster, code, verb) (increase(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET|POST|PUT|PATCH|DELETE\",code=~\"3..\"}[1h]))\n    \"record\": \"code_verb:apiserver_request_total:increase1h\"\n  - \"expr\": |\n      sum by (cluster, code, verb) (increase(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET|POST|PUT|PATCH|DELETE\",code=~\"4..\"}[1h]))\n    \"record\": \"code_verb:apiserver_request_total:increase1h\"\n  - \"expr\": |\n      sum by (cluster, code, verb) (increase(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET|POST|PUT|PATCH|DELETE\",code=~\"5..\"}[1h]))\n    \"record\": \"code_verb:apiserver_request_total:increase1h\"\n- \"name\": \"kube-apiserver-burnrate.rules\"\n  \"rules\":\n  - \"expr\": |\n      (\n        (\n          # too slow\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\"}[1d]))\n          -\n          (\n            (\n              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=~\"resource|\",le=~\"1(\\\\.0)?\"}[1d]))\n              or\n              vector(0)\n            )\n            +\n            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=\"namespace\",le=~\"5(\\\\.0)?\"}[1d]))\n            +\n            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=\"cluster\",le=~\"30(\\\\.0)?\"}[1d]))\n          )\n        )\n        +\n        # errors\n        sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET\",code=~\"5..\"}[1d]))\n      )\n      /\n      sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET\"}[1d]))\n    \"labels\":\n      \"verb\": \"read\"\n    \"record\": \"apiserver_request:burnrate1d\"\n  - \"expr\": |\n      (\n        (\n          # too slow\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\"}[1h]))\n          -\n          (\n            (\n              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=~\"resource|\",le=~\"1(\\\\.0)?\"}[1h]))\n              or\n              vector(0)\n            )\n            +\n            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=\"namespace\",le=~\"5(\\\\.0)?\"}[1h]))\n            +\n            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=\"cluster\",le=~\"30(\\\\.0)?\"}[1h]))\n          )\n        )\n        +\n        # errors\n        sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET\",code=~\"5..\"}[1h]))\n      )\n      /\n      sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET\"}[1h]))\n    \"labels\":\n      \"verb\": \"read\"\n    \"record\": \"apiserver_request:burnrate1h\"\n  - \"expr\": |\n      (\n        (\n          # too slow\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\"}[2h]))\n          -\n          (\n            (\n              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=~\"resource|\",le=~\"1(\\\\.0)?\"}[2h]))\n              or\n              vector(0)\n            )\n            +\n            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=\"namespace\",le=~\"5(\\\\.0)?\"}[2h]))\n            +\n            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=\"cluster\",le=~\"30(\\\\.0)?\"}[2h]))\n          )\n        )\n        +\n        # errors\n        sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET\",code=~\"5..\"}[2h]))\n      )\n      /\n      sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET\"}[2h]))\n    \"labels\":\n      \"verb\": \"read\"\n    \"record\": \"apiserver_request:burnrate2h\"\n  - \"expr\": |\n      (\n        (\n          # too slow\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\"}[30m]))\n          -\n          (\n            (\n              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=~\"resource|\",le=~\"1(\\\\.0)?\"}[30m]))\n              or\n              vector(0)\n            )\n            +\n            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=\"namespace\",le=~\"5(\\\\.0)?\"}[30m]))\n            +\n            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=\"cluster\",le=~\"30(\\\\.0)?\"}[30m]))\n          )\n        )\n        +\n        # errors\n        sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET\",code=~\"5..\"}[30m]))\n      )\n      /\n      sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET\"}[30m]))\n    \"labels\":\n      \"verb\": \"read\"\n    \"record\": \"apiserver_request:burnrate30m\"\n  - \"expr\": |\n      (\n        (\n          # too slow\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\"}[3d]))\n          -\n          (\n            (\n              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=~\"resource|\",le=~\"1(\\\\.0)?\"}[3d]))\n              or\n              vector(0)\n            )\n            +\n            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=\"namespace\",le=~\"5(\\\\.0)?\"}[3d]))\n            +\n            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=\"cluster\",le=~\"30(\\\\.0)?\"}[3d]))\n          )\n        )\n        +\n        # errors\n        sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET\",code=~\"5..\"}[3d]))\n      )\n      /\n      sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET\"}[3d]))\n    \"labels\":\n      \"verb\": \"read\"\n    \"record\": \"apiserver_request:burnrate3d\"\n  - \"expr\": |\n      (\n        (\n          # too slow\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\"}[5m]))\n          -\n          (\n            (\n              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=~\"resource|\",le=~\"1(\\\\.0)?\"}[5m]))\n              or\n              vector(0)\n            )\n            +\n            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=\"namespace\",le=~\"5(\\\\.0)?\"}[5m]))\n            +\n            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=\"cluster\",le=~\"30(\\\\.0)?\"}[5m]))\n          )\n        )\n        +\n        # errors\n        sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET\",code=~\"5..\"}[5m]))\n      )\n      /\n      sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET\"}[5m]))\n    \"labels\":\n      \"verb\": \"read\"\n    \"record\": \"apiserver_request:burnrate5m\"\n  - \"expr\": |\n      (\n        (\n          # too slow\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\"}[6h]))\n          -\n          (\n            (\n              sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=~\"resource|\",le=~\"1(\\\\.0)?\"}[6h]))\n              or\n              vector(0)\n            )\n            +\n            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=\"namespace\",le=~\"5(\\\\.0)?\"}[6h]))\n            +\n            sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\",scope=\"cluster\",le=~\"30(\\\\.0)?\"}[6h]))\n          )\n        )\n        +\n        # errors\n        sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET\",code=~\"5..\"}[6h]))\n      )\n      /\n      sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"LIST|GET\"}[6h]))\n    \"labels\":\n      \"verb\": \"read\"\n    \"record\": \"apiserver_request:burnrate6h\"\n  - \"expr\": |\n      (\n        (\n          # too slow\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",subresource!~\"proxy|attach|log|exec|portforward\"}[1d]))\n          -\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",subresource!~\"proxy|attach|log|exec|portforward\",le=~\"1(\\\\.0)?\"}[1d]))\n        )\n        +\n        sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",code=~\"5..\"}[1d]))\n      )\n      /\n      sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\"}[1d]))\n    \"labels\":\n      \"verb\": \"write\"\n    \"record\": \"apiserver_request:burnrate1d\"\n  - \"expr\": |\n      (\n        (\n          # too slow\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",subresource!~\"proxy|attach|log|exec|portforward\"}[1h]))\n          -\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",subresource!~\"proxy|attach|log|exec|portforward\",le=~\"1(\\\\.0)?\"}[1h]))\n        )\n        +\n        sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",code=~\"5..\"}[1h]))\n      )\n      /\n      sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\"}[1h]))\n    \"labels\":\n      \"verb\": \"write\"\n    \"record\": \"apiserver_request:burnrate1h\"\n  - \"expr\": |\n      (\n        (\n          # too slow\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",subresource!~\"proxy|attach|log|exec|portforward\"}[2h]))\n          -\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",subresource!~\"proxy|attach|log|exec|portforward\",le=~\"1(\\\\.0)?\"}[2h]))\n        )\n        +\n        sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",code=~\"5..\"}[2h]))\n      )\n      /\n      sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\"}[2h]))\n    \"labels\":\n      \"verb\": \"write\"\n    \"record\": \"apiserver_request:burnrate2h\"\n  - \"expr\": |\n      (\n        (\n          # too slow\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",subresource!~\"proxy|attach|log|exec|portforward\"}[30m]))\n          -\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",subresource!~\"proxy|attach|log|exec|portforward\",le=~\"1(\\\\.0)?\"}[30m]))\n        )\n        +\n        sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",code=~\"5..\"}[30m]))\n      )\n      /\n      sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\"}[30m]))\n    \"labels\":\n      \"verb\": \"write\"\n    \"record\": \"apiserver_request:burnrate30m\"\n  - \"expr\": |\n      (\n        (\n          # too slow\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",subresource!~\"proxy|attach|log|exec|portforward\"}[3d]))\n          -\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",subresource!~\"proxy|attach|log|exec|portforward\",le=~\"1(\\\\.0)?\"}[3d]))\n        )\n        +\n        sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",code=~\"5..\"}[3d]))\n      )\n      /\n      sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\"}[3d]))\n    \"labels\":\n      \"verb\": \"write\"\n    \"record\": \"apiserver_request:burnrate3d\"\n  - \"expr\": |\n      (\n        (\n          # too slow\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",subresource!~\"proxy|attach|log|exec|portforward\"}[5m]))\n          -\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",subresource!~\"proxy|attach|log|exec|portforward\",le=~\"1(\\\\.0)?\"}[5m]))\n        )\n        +\n        sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",code=~\"5..\"}[5m]))\n      )\n      /\n      sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\"}[5m]))\n    \"labels\":\n      \"verb\": \"write\"\n    \"record\": \"apiserver_request:burnrate5m\"\n  - \"expr\": |\n      (\n        (\n          # too slow\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_count{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",subresource!~\"proxy|attach|log|exec|portforward\"}[6h]))\n          -\n          sum by (cluster) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",subresource!~\"proxy|attach|log|exec|portforward\",le=~\"1(\\\\.0)?\"}[6h]))\n        )\n        +\n        sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",code=~\"5..\"}[6h]))\n      )\n      /\n      sum by (cluster) (rate(apiserver_request_total{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\"}[6h]))\n    \"labels\":\n      \"verb\": \"write\"\n    \"record\": \"apiserver_request:burnrate6h\"\n- \"name\": \"kube-apiserver-histogram.rules\"\n  \"rules\":\n  - \"expr\": |\n      histogram_quantile(0.99, sum by (cluster, le, resource) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"LIST|GET\",subresource!~\"proxy|attach|log|exec|portforward\"}[5m]))) > 0\n    \"labels\":\n      \"quantile\": \"0.99\"\n      \"verb\": \"read\"\n    \"record\": \"cluster_quantile:apiserver_request_sli_duration_seconds:histogram_quantile\"\n  - \"expr\": |\n      histogram_quantile(0.99, sum by (cluster, le, resource) (rate(apiserver_request_sli_duration_seconds_bucket{job=\"kube-apiserver\",verb=~\"POST|PUT|PATCH|DELETE\",subresource!~\"proxy|attach|log|exec|portforward\"}[5m]))) > 0\n    \"labels\":\n      \"quantile\": \"0.99\"\n      \"verb\": \"write\"\n    \"record\": \"cluster_quantile:apiserver_request_sli_duration_seconds:histogram_quantile\"\n- \"name\": \"k8s.rules.container_cpu_usage_seconds_total\"\n  \"rules\":\n  - \"expr\": |\n      sum by (cluster, namespace, pod, container) (\n        irate(container_cpu_usage_seconds_total{job=\"cadvisor\", image!=\"\"}[5m])\n      ) * on (cluster, namespace, pod) group_left(node) topk by (cluster, namespace, pod) (\n        1, max by(cluster, namespace, pod, node) (kube_pod_info{node!=\"\"})\n      )\n    \"record\": \"node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate\"\n- \"name\": \"k8s.rules.container_memory_working_set_bytes\"\n  \"rules\":\n  - \"expr\": |\n      container_memory_working_set_bytes{job=\"cadvisor\", image!=\"\"}\n      * on (cluster, namespace, pod) group_left(node) topk by(cluster, namespace, pod) (1,\n        max by(cluster, namespace, pod, node) (kube_pod_info{node!=\"\"})\n      )\n    \"record\": \"node_namespace_pod_container:container_memory_working_set_bytes\"\n- \"name\": \"k8s.rules.container_memory_rss\"\n  \"rules\":\n  - \"expr\": |\n      container_memory_rss{job=\"cadvisor\", image!=\"\"}\n      * on (cluster, namespace, pod) group_left(node) topk by(cluster, namespace, pod) (1,\n        max by(cluster, namespace, pod, node) (kube_pod_info{node!=\"\"})\n      )\n    \"record\": \"node_namespace_pod_container:container_memory_rss\"\n- \"name\": \"k8s.rules.container_memory_cache\"\n  \"rules\":\n  - \"expr\": |\n      container_memory_cache{job=\"cadvisor\", image!=\"\"}\n      * on (cluster, namespace, pod) group_left(node) topk by(cluster, namespace, pod) (1,\n        max by(cluster, namespace, pod, node) (kube_pod_info{node!=\"\"})\n      )\n    \"record\": \"node_namespace_pod_container:container_memory_cache\"\n- \"name\": \"k8s.rules.container_memory_swap\"\n  \"rules\":\n  - \"expr\": |\n      container_memory_swap{job=\"cadvisor\", image!=\"\"}\n      * on (cluster, namespace, pod) group_left(node) topk by(cluster, namespace, pod) (1,\n        max by(cluster, namespace, pod, node) (kube_pod_info{node!=\"\"})\n      )\n    \"record\": \"node_namespace_pod_container:container_memory_swap\"\n- \"name\": \"k8s.rules.container_memory_requests\"\n  \"rules\":\n  - \"expr\": |\n      kube_pod_container_resource_requests{resource=\"memory\",job=\"kube-state-metrics\"}  * on (namespace, pod, cluster)\n      group_left() max by (namespace, pod, cluster) (\n        (kube_pod_status_phase{phase=~\"Pending|Running\"} == 1)\n      )\n    \"record\": \"cluster:namespace:pod_memory:active:kube_pod_container_resource_requests\"\n  - \"expr\": |\n      sum by (namespace, cluster) (\n          sum by (namespace, pod, cluster) (\n              max by (namespace, pod, container, cluster) (\n                kube_pod_container_resource_requests{resource=\"memory\",job=\"kube-state-metrics\"}\n              ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (\n                kube_pod_status_phase{phase=~\"Pending|Running\"} == 1\n              )\n          )\n      )\n    \"record\": \"namespace_memory:kube_pod_container_resource_requests:sum\"\n- \"name\": \"k8s.rules.container_cpu_requests\"\n  \"rules\":\n  - \"expr\": |\n      kube_pod_container_resource_requests{resource=\"cpu\",job=\"kube-state-metrics\"}  * on (namespace, pod, cluster)\n      group_left() max by (namespace, pod, cluster) (\n        (kube_pod_status_phase{phase=~\"Pending|Running\"} == 1)\n      )\n    \"record\": \"cluster:namespace:pod_cpu:active:kube_pod_container_resource_requests\"\n  - \"expr\": |\n      sum by (namespace, cluster) (\n          sum by (namespace, pod, cluster) (\n              max by (namespace, pod, container, cluster) (\n                kube_pod_container_resource_requests{resource=\"cpu\",job=\"kube-state-metrics\"}\n              ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (\n                kube_pod_status_phase{phase=~\"Pending|Running\"} == 1\n              )\n          )\n      )\n    \"record\": \"namespace_cpu:kube_pod_container_resource_requests:sum\"\n- \"name\": \"k8s.rules.container_memory_limits\"\n  \"rules\":\n  - \"expr\": |\n      kube_pod_container_resource_limits{resource=\"memory\",job=\"kube-state-metrics\"}  * on (namespace, pod, cluster)\n      group_left() max by (namespace, pod, cluster) (\n        (kube_pod_status_phase{phase=~\"Pending|Running\"} == 1)\n      )\n    \"record\": \"cluster:namespace:pod_memory:active:kube_pod_container_resource_limits\"\n  - \"expr\": |\n      sum by (namespace, cluster) (\n          sum by (namespace, pod, cluster) (\n              max by (namespace, pod, container, cluster) (\n                kube_pod_container_resource_limits{resource=\"memory\",job=\"kube-state-metrics\"}\n              ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (\n                kube_pod_status_phase{phase=~\"Pending|Running\"} == 1\n              )\n          )\n      )\n    \"record\": \"namespace_memory:kube_pod_container_resource_limits:sum\"\n- \"name\": \"k8s.rules.container_cpu_limits\"\n  \"rules\":\n  - \"expr\": |\n      kube_pod_container_resource_limits{resource=\"cpu\",job=\"kube-state-metrics\"}  * on (namespace, pod, cluster)\n      group_left() max by (namespace, pod, cluster) (\n       (kube_pod_status_phase{phase=~\"Pending|Running\"} == 1)\n       )\n    \"record\": \"cluster:namespace:pod_cpu:active:kube_pod_container_resource_limits\"\n  - \"expr\": |\n      sum by (namespace, cluster) (\n          sum by (namespace, pod, cluster) (\n              max by (namespace, pod, container, cluster) (\n                kube_pod_container_resource_limits{resource=\"cpu\",job=\"kube-state-metrics\"}\n              ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (\n                kube_pod_status_phase{phase=~\"Pending|Running\"} == 1\n              )\n          )\n      )\n    \"record\": \"namespace_cpu:kube_pod_container_resource_limits:sum\"\n- \"name\": \"k8s.rules.pod_owner\"\n  \"rules\":\n  - \"expr\": |\n      max by (cluster, namespace, workload, pod) (\n        label_replace(\n          label_replace(\n            kube_pod_owner{job=\"kube-state-metrics\", owner_kind=\"ReplicaSet\"},\n            \"replicaset\", \"$1\", \"owner_name\", \"(.*)\"\n          ) * on(replicaset, namespace) group_left(owner_name) topk by(replicaset, namespace) (\n            1, max by (replicaset, namespace, owner_name) (\n              kube_replicaset_owner{job=\"kube-state-metrics\"}\n            )\n          ),\n          \"workload\", \"$1\", \"owner_name\", \"(.*)\"\n        )\n      )\n    \"labels\":\n      \"workload_type\": \"deployment\"\n    \"record\": \"namespace_workload_pod:kube_pod_owner:relabel\"\n  - \"expr\": |\n      max by (cluster, namespace, workload, pod) (\n        label_replace(\n          kube_pod_owner{job=\"kube-state-metrics\", owner_kind=\"DaemonSet\"},\n          \"workload\", \"$1\", \"owner_name\", \"(.*)\"\n        )\n      )\n    \"labels\":\n      \"workload_type\": \"daemonset\"\n    \"record\": \"namespace_workload_pod:kube_pod_owner:relabel\"\n  - \"expr\": |\n      max by (cluster, namespace, workload, pod) (\n        label_replace(\n          kube_pod_owner{job=\"kube-state-metrics\", owner_kind=\"StatefulSet\"},\n          \"workload\", \"$1\", \"owner_name\", \"(.*)\"\n        )\n      )\n    \"labels\":\n      \"workload_type\": \"statefulset\"\n    \"record\": \"namespace_workload_pod:kube_pod_owner:relabel\"\n  - \"expr\": |\n      max by (cluster, namespace, workload, pod) (\n        label_replace(\n          kube_pod_owner{job=\"kube-state-metrics\", owner_kind=\"Job\"},\n          \"workload\", \"$1\", \"owner_name\", \"(.*)\"\n        )\n      )\n    \"labels\":\n      \"workload_type\": \"job\"\n    \"record\": \"namespace_workload_pod:kube_pod_owner:relabel\"\n- \"name\": \"kube-scheduler.rules\"\n  \"rules\":\n  - \"expr\": |\n      histogram_quantile(0.99, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job=\"kube-scheduler\"}[5m])) without(instance, pod))\n    \"labels\":\n      \"quantile\": \"0.99\"\n    \"record\": \"cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile\"\n  - \"expr\": |\n      histogram_quantile(0.99, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job=\"kube-scheduler\"}[5m])) without(instance, pod))\n    \"labels\":\n      \"quantile\": \"0.99\"\n    \"record\": \"cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile\"\n  - \"expr\": |\n      histogram_quantile(0.99, sum(rate(scheduler_binding_duration_seconds_bucket{job=\"kube-scheduler\"}[5m])) without(instance, pod))\n    \"labels\":\n      \"quantile\": \"0.99\"\n    \"record\": \"cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile\"\n  - \"expr\": |\n      histogram_quantile(0.9, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job=\"kube-scheduler\"}[5m])) without(instance, pod))\n    \"labels\":\n      \"quantile\": \"0.9\"\n    \"record\": \"cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile\"\n  - \"expr\": |\n      histogram_quantile(0.9, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job=\"kube-scheduler\"}[5m])) without(instance, pod))\n    \"labels\":\n      \"quantile\": \"0.9\"\n    \"record\": \"cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile\"\n  - \"expr\": |\n      histogram_quantile(0.9, sum(rate(scheduler_binding_duration_seconds_bucket{job=\"kube-scheduler\"}[5m])) without(instance, pod))\n    \"labels\":\n      \"quantile\": \"0.9\"\n    \"record\": \"cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile\"\n  - \"expr\": |\n      histogram_quantile(0.5, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job=\"kube-scheduler\"}[5m])) without(instance, pod))\n    \"labels\":\n      \"quantile\": \"0.5\"\n    \"record\": \"cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile\"\n  - \"expr\": |\n      histogram_quantile(0.5, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job=\"kube-scheduler\"}[5m])) without(instance, pod))\n    \"labels\":\n      \"quantile\": \"0.5\"\n    \"record\": \"cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile\"\n  - \"expr\": |\n      histogram_quantile(0.5, sum(rate(scheduler_binding_duration_seconds_bucket{job=\"kube-scheduler\"}[5m])) without(instance, pod))\n    \"labels\":\n      \"quantile\": \"0.5\"\n    \"record\": \"cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile\"\n- \"name\": \"node.rules\"\n  \"rules\":\n  - \"expr\": |\n      topk by(cluster, namespace, pod) (1,\n        max by (cluster, node, namespace, pod) (\n          label_replace(kube_pod_info{job=\"kube-state-metrics\",node!=\"\"}, \"pod\", \"$1\", \"pod\", \"(.*)\")\n      ))\n    \"record\": \"node_namespace_pod:kube_pod_info:\"\n  - \"expr\": |\n      count by (cluster, node) (\n        node_cpu_seconds_total{mode=\"idle\",job=\"node-exporter\"}\n        * on (cluster, namespace, pod) group_left(node)\n        topk by(cluster, namespace, pod) (1, node_namespace_pod:kube_pod_info:)\n      )\n    \"record\": \"node:node_num_cpu:sum\"\n  - \"expr\": |\n      sum(\n        node_memory_MemAvailable_bytes{job=\"node-exporter\"} or\n        (\n          node_memory_Buffers_bytes{job=\"node-exporter\"} +\n          node_memory_Cached_bytes{job=\"node-exporter\"} +\n          node_memory_MemFree_bytes{job=\"node-exporter\"} +\n          node_memory_Slab_bytes{job=\"node-exporter\"}\n        )\n      ) by (cluster)\n    \"record\": \":node_memory_MemAvailable_bytes:sum\"\n  - \"expr\": |\n      avg by (cluster, node) (\n        sum without (mode) (\n          rate(node_cpu_seconds_total{mode!=\"idle\",mode!=\"iowait\",mode!=\"steal\",job=\"node-exporter\"}[5m])\n        )\n      )\n    \"record\": \"node:node_cpu_utilization:ratio_rate5m\"\n  - \"expr\": |\n      avg by (cluster) (\n        node:node_cpu_utilization:ratio_rate5m\n      )\n    \"record\": \"cluster:node_cpu:ratio_rate5m\"\n- \"name\": \"kubelet.rules\"\n  \"rules\":\n  - \"expr\": |\n      histogram_quantile(0.99, sum(rate(kubelet_pleg_relist_duration_seconds_bucket{job=\"kubelet\"}[5m])) by (cluster, instance, le) * on(cluster, instance) group_left(node) kubelet_node_name{job=\"kubelet\"})\n    \"labels\":\n      \"quantile\": \"0.99\"\n    \"record\": \"node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile\"\n  - \"expr\": |\n      histogram_quantile(0.9, sum(rate(kubelet_pleg_relist_duration_seconds_bucket{job=\"kubelet\"}[5m])) by (cluster, instance, le) * on(cluster, instance) group_left(node) kubelet_node_name{job=\"kubelet\"})\n    \"labels\":\n      \"quantile\": \"0.9\"\n    \"record\": \"node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile\"\n  - \"expr\": |\n      histogram_quantile(0.5, sum(rate(kubelet_pleg_relist_duration_seconds_bucket{job=\"kubelet\"}[5m])) by (cluster, instance, le) * on(cluster, instance) group_left(node) kubelet_node_name{job=\"kubelet\"})\n    \"labels\":\n      \"quantile\": \"0.5\"\n    \"record\": \"node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile\"\n- \"name\": \"windows.node.rules\"\n  \"rules\":\n  - \"expr\": |\n      count by (cluster) (\n        windows_system_system_up_time{job=\"kubernetes-windows-exporter\"}\n      )\n    \"record\": \"node:windows_node:sum\"\n  - \"expr\": |\n      count by (cluster, instance) (sum by (cluster, instance, core) (\n        windows_cpu_time_total{job=\"kubernetes-windows-exporter\"}\n      ))\n    \"record\": \"node:windows_node_num_cpu:sum\"\n  - \"expr\": |\n      1 - avg by (cluster) (rate(windows_cpu_time_total{job=\"kubernetes-windows-exporter\",mode=\"idle\"}[1m]))\n    \"record\": \":windows_node_cpu_utilisation:avg1m\"\n  - \"expr\": |\n      1 - avg by (cluster, instance) (\n        rate(windows_cpu_time_total{job=\"kubernetes-windows-exporter\",mode=\"idle\"}[1m])\n      )\n    \"record\": \"node:windows_node_cpu_utilisation:avg1m\"\n  - \"expr\": |\n      1 -\n      sum by (cluster) (windows_memory_available_bytes{job=\"kubernetes-windows-exporter\"})\n      /\n      sum by (cluster) (windows_os_visible_memory_bytes{job=\"kubernetes-windows-exporter\"})\n    \"record\": \":windows_node_memory_utilisation:\"\n  - \"expr\": |\n      sum by (cluster) (windows_memory_available_bytes{job=\"kubernetes-windows-exporter\"} + windows_memory_cache_bytes{job=\"kubernetes-windows-exporter\"})\n    \"record\": \":windows_node_memory_MemFreeCached_bytes:sum\"\n  - \"expr\": |\n      (windows_memory_cache_bytes{job=\"kubernetes-windows-exporter\"} + windows_memory_modified_page_list_bytes{job=\"kubernetes-windows-exporter\"} + windows_memory_standby_cache_core_bytes{job=\"kubernetes-windows-exporter\"} + windows_memory_standby_cache_normal_priority_bytes{job=\"kubernetes-windows-exporter\"} + windows_memory_standby_cache_reserve_bytes{job=\"kubernetes-windows-exporter\"})\n    \"record\": \"node:windows_node_memory_totalCached_bytes:sum\"\n  - \"expr\": |\n      sum by (cluster) (windows_os_visible_memory_bytes{job=\"kubernetes-windows-exporter\"})\n    \"record\": \":windows_node_memory_MemTotal_bytes:sum\"\n  - \"expr\": |\n      sum by (cluster, instance) (\n        (windows_memory_available_bytes{job=\"kubernetes-windows-exporter\"})\n      )\n    \"record\": \"node:windows_node_memory_bytes_available:sum\"\n  - \"expr\": |\n      sum by (cluster, instance) (\n        windows_os_visible_memory_bytes{job=\"kubernetes-windows-exporter\"}\n      )\n    \"record\": \"node:windows_node_memory_bytes_total:sum\"\n  - \"expr\": |\n      (node:windows_node_memory_bytes_total:sum - node:windows_node_memory_bytes_available:sum)\n      /\n      scalar(sum(node:windows_node_memory_bytes_total:sum))\n    \"record\": \"node:windows_node_memory_utilisation:ratio\"\n  - \"expr\": |\n      1 - (node:windows_node_memory_bytes_available:sum / node:windows_node_memory_bytes_total:sum)\n    \"record\": \"node:windows_node_memory_utilisation:\"\n  - \"expr\": |\n      irate(windows_memory_swap_page_operations_total{job=\"kubernetes-windows-exporter\"}[5m])\n    \"record\": \"node:windows_node_memory_swap_io_pages:irate\"\n  - \"expr\": |\n      avg by (cluster) (irate(windows_logical_disk_read_seconds_total{job=\"kubernetes-windows-exporter\"}[1m]) +\n          irate(windows_logical_disk_write_seconds_total{job=\"kubernetes-windows-exporter\"}[1m])\n        )\n    \"record\": \":windows_node_disk_utilisation:avg_irate\"\n  - \"expr\": |\n      avg by (cluster, instance) (\n        (irate(windows_logical_disk_read_seconds_total{job=\"kubernetes-windows-exporter\"}[1m]) +\n         irate(windows_logical_disk_write_seconds_total{job=\"kubernetes-windows-exporter\"}[1m]))\n      )\n    \"record\": \"node:windows_node_disk_utilisation:avg_irate\"\n  - \"expr\": |\n      max by (cluster,instance,volume)(\n        (windows_logical_disk_size_bytes{job=\"kubernetes-windows-exporter\"}\n      - windows_logical_disk_free_bytes{job=\"kubernetes-windows-exporter\"})\n      / windows_logical_disk_size_bytes{job=\"kubernetes-windows-exporter\"}\n      )\n    \"record\": \"node:windows_node_filesystem_usage:\"\n  - \"expr\": |\n      max by (cluster, instance, volume) (windows_logical_disk_free_bytes{job=\"kubernetes-windows-exporter\"} / windows_logical_disk_size_bytes{job=\"kubernetes-windows-exporter\"})\n    \"record\": \"node:windows_node_filesystem_avail:\"\n  - \"expr\": |\n      sum by (cluster) (irate(windows_net_bytes_total{job=\"kubernetes-windows-exporter\"}[1m]))\n    \"record\": \":windows_node_net_utilisation:sum_irate\"\n  - \"expr\": |\n      sum by (cluster, instance) (\n        (irate(windows_net_bytes_total{job=\"kubernetes-windows-exporter\"}[1m]))\n      )\n    \"record\": \"node:windows_node_net_utilisation:sum_irate\"\n  - \"expr\": |\n      sum by (cluster) (irate(windows_net_packets_received_discarded_total{job=\"kubernetes-windows-exporter\"}[1m])) +\n      sum by (cluster) (irate(windows_net_packets_outbound_discarded_total{job=\"kubernetes-windows-exporter\"}[1m]))\n    \"record\": \":windows_node_net_saturation:sum_irate\"\n  - \"expr\": |\n      sum by (cluster, instance) (\n        (irate(windows_net_packets_received_discarded_total{job=\"kubernetes-windows-exporter\"}[1m]) +\n        irate(windows_net_packets_outbound_discarded_total{job=\"kubernetes-windows-exporter\"}[1m]))\n      )\n    \"record\": \"node:windows_node_net_saturation:sum_irate\"\n- \"name\": \"windows.pod.rules\"\n  \"rules\":\n  - \"expr\": |\n      windows_container_available{job=\"kubernetes-windows-exporter\", container_id != \"\"} * on(container_id, cluster) group_left(container, pod, namespace) max(kube_pod_container_info{job=\"kube-state-metrics\", container_id != \"\"}) by(container, container_id, pod, namespace, cluster)\n    \"record\": \"windows_pod_container_available\"\n  - \"expr\": |\n      windows_container_cpu_usage_seconds_total{job=\"kubernetes-windows-exporter\", container_id != \"\"} * on(container_id, cluster) group_left(container, pod, namespace) max(kube_pod_container_info{job=\"kube-state-metrics\", container_id != \"\"}) by(container, container_id, pod, namespace, cluster)\n    \"record\": \"windows_container_total_runtime\"\n  - \"expr\": |\n      windows_container_memory_usage_commit_bytes{job=\"kubernetes-windows-exporter\", container_id != \"\"} * on(container_id, cluster) group_left(container, pod, namespace) max(kube_pod_container_info{job=\"kube-state-metrics\", container_id != \"\"}) by(container, container_id, pod, namespace, cluster)\n    \"record\": \"windows_container_memory_usage\"\n  - \"expr\": |\n      windows_container_memory_usage_private_working_set_bytes{job=\"kubernetes-windows-exporter\", container_id != \"\"} * on(container_id, cluster) group_left(container, pod, namespace) max(kube_pod_container_info{job=\"kube-state-metrics\", container_id != \"\"}) by(container, container_id, pod, namespace, cluster)\n    \"record\": \"windows_container_private_working_set_usage\"\n  - \"expr\": |\n      windows_container_network_receive_bytes_total{job=\"kubernetes-windows-exporter\", container_id != \"\"} * on(container_id, cluster) group_left(container, pod, namespace) max(kube_pod_container_info{job=\"kube-state-metrics\", container_id != \"\"}) by(container, container_id, pod, namespace, cluster)\n    \"record\": \"windows_container_network_received_bytes_total\"\n  - \"expr\": |\n      windows_container_network_transmit_bytes_total{job=\"kubernetes-windows-exporter\", container_id != \"\"} * on(container_id, cluster) group_left(container, pod, namespace) max(kube_pod_container_info{job=\"kube-state-metrics\", container_id != \"\"}) by(container, container_id, pod, namespace, cluster)\n    \"record\": \"windows_container_network_transmitted_bytes_total\"\n  - \"expr\": |\n      max by (cluster, namespace, pod, container) (\n        kube_pod_container_resource_requests{resource=\"memory\",job=\"kube-state-metrics\"}\n      ) * on(container,pod,namespace,cluster) (windows_pod_container_available)\n    \"record\": \"kube_pod_windows_container_resource_memory_request\"\n  - \"expr\": |\n      kube_pod_container_resource_limits{resource=\"memory\",job=\"kube-state-metrics\"} * on(container,pod,namespace,cluster) (windows_pod_container_available)\n    \"record\": \"kube_pod_windows_container_resource_memory_limit\"\n  - \"expr\": |\n      max by (cluster, namespace, pod, container) (\n        kube_pod_container_resource_requests{resource=\"cpu\",job=\"kube-state-metrics\"}\n      ) * on(container,pod,namespace,cluster) (windows_pod_container_available)\n    \"record\": \"kube_pod_windows_container_resource_cpu_cores_request\"\n  - \"expr\": |\n      kube_pod_container_resource_limits{resource=\"cpu\",job=\"kube-state-metrics\"} * on(container,pod,namespace,cluster) (windows_pod_container_available)\n    \"record\": \"kube_pod_windows_container_resource_cpu_cores_limit\"\n  - \"expr\": |\n      sum by (cluster, namespace, pod, container) (\n        rate(windows_container_total_runtime{}[5m])\n      )\n    \"record\": \"namespace_pod_container:windows_container_cpu_usage_seconds_total:sum_rate\""
  "node.alerting.rules.yaml": "\"groups\":\n- \"name\": \"node-exporter\"\n  \"rules\":\n  - \"alert\": \"NodeFilesystemSpaceFillingUp\"\n    \"annotations\":\n      \"description\": \"Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint }}, at {{ $labels.instance }} has only {{ printf \\\"%.2f\\\" $value }}% available space left and is filling up.\"\n      \"summary\": \"Filesystem is predicted to run out of space within the next 24 hours.\"\n    \"expr\": |\n      (\n        node_filesystem_avail_bytes{job=\"node\",fstype!=\"\",mountpoint!=\"\"} / node_filesystem_size_bytes{job=\"node\",fstype!=\"\",mountpoint!=\"\"} * 100 < 40\n      and\n        predict_linear(node_filesystem_avail_bytes{job=\"node\",fstype!=\"\",mountpoint!=\"\"}[6h], 24*60*60) < 0\n      and\n        node_filesystem_readonly{job=\"node\",fstype!=\"\",mountpoint!=\"\"} == 0\n      )\n    \"for\": \"1h\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeFilesystemSpaceFillingUp\"\n    \"annotations\":\n      \"description\": \"Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint }}, at {{ $labels.instance }} has only {{ printf \\\"%.2f\\\" $value }}% available space left and is filling up fast.\"\n      \"summary\": \"Filesystem is predicted to run out of space within the next 4 hours.\"\n    \"expr\": |\n      (\n        node_filesystem_avail_bytes{job=\"node\",fstype!=\"\",mountpoint!=\"\"} / node_filesystem_size_bytes{job=\"node\",fstype!=\"\",mountpoint!=\"\"} * 100 < 20\n      and\n        predict_linear(node_filesystem_avail_bytes{job=\"node\",fstype!=\"\",mountpoint!=\"\"}[6h], 4*60*60) < 0\n      and\n        node_filesystem_readonly{job=\"node\",fstype!=\"\",mountpoint!=\"\"} == 0\n      )\n    \"for\": \"1h\"\n    \"labels\":\n      \"severity\": \"critical\"\n  - \"alert\": \"NodeFilesystemAlmostOutOfSpace\"\n    \"annotations\":\n      \"description\": \"Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint }}, at {{ $labels.instance }} has only {{ printf \\\"%.2f\\\" $value }}% available space left.\"\n      \"summary\": \"Filesystem has less than 5% space left.\"\n    \"expr\": |\n      (\n        node_filesystem_avail_bytes{job=\"node\",fstype!=\"\",mountpoint!=\"\"} / node_filesystem_size_bytes{job=\"node\",fstype!=\"\",mountpoint!=\"\"} * 100 < 5\n      and\n        node_filesystem_readonly{job=\"node\",fstype!=\"\",mountpoint!=\"\"} == 0\n      )\n    \"for\": \"30m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeFilesystemAlmostOutOfSpace\"\n    \"annotations\":\n      \"description\": \"Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint }}, at {{ $labels.instance }} has only {{ printf \\\"%.2f\\\" $value }}% available space left.\"\n      \"summary\": \"Filesystem has less than 3% space left.\"\n    \"expr\": |\n      (\n        node_filesystem_avail_bytes{job=\"node\",fstype!=\"\",mountpoint!=\"\"} / node_filesystem_size_bytes{job=\"node\",fstype!=\"\",mountpoint!=\"\"} * 100 < 3\n      and\n        node_filesystem_readonly{job=\"node\",fstype!=\"\",mountpoint!=\"\"} == 0\n      )\n    \"for\": \"30m\"\n    \"labels\":\n      \"severity\": \"critical\"\n  - \"alert\": \"NodeFilesystemFilesFillingUp\"\n    \"annotations\":\n      \"description\": \"Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint }}, at {{ $labels.instance }} has only {{ printf \\\"%.2f\\\" $value }}% available inodes left and is filling up.\"\n      \"summary\": \"Filesystem is predicted to run out of inodes within the next 24 hours.\"\n    \"expr\": |\n      (\n        node_filesystem_files_free{job=\"node\",fstype!=\"\",mountpoint!=\"\"} / node_filesystem_files{job=\"node\",fstype!=\"\",mountpoint!=\"\"} * 100 < 40\n      and\n        predict_linear(node_filesystem_files_free{job=\"node\",fstype!=\"\",mountpoint!=\"\"}[6h], 24*60*60) < 0\n      and\n        node_filesystem_readonly{job=\"node\",fstype!=\"\",mountpoint!=\"\"} == 0\n      )\n    \"for\": \"1h\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeFilesystemFilesFillingUp\"\n    \"annotations\":\n      \"description\": \"Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint }}, at {{ $labels.instance }} has only {{ printf \\\"%.2f\\\" $value }}% available inodes left and is filling up fast.\"\n      \"summary\": \"Filesystem is predicted to run out of inodes within the next 4 hours.\"\n    \"expr\": |\n      (\n        node_filesystem_files_free{job=\"node\",fstype!=\"\",mountpoint!=\"\"} / node_filesystem_files{job=\"node\",fstype!=\"\",mountpoint!=\"\"} * 100 < 20\n      and\n        predict_linear(node_filesystem_files_free{job=\"node\",fstype!=\"\",mountpoint!=\"\"}[6h], 4*60*60) < 0\n      and\n        node_filesystem_readonly{job=\"node\",fstype!=\"\",mountpoint!=\"\"} == 0\n      )\n    \"for\": \"1h\"\n    \"labels\":\n      \"severity\": \"critical\"\n  - \"alert\": \"NodeFilesystemAlmostOutOfFiles\"\n    \"annotations\":\n      \"description\": \"Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint }}, at {{ $labels.instance }} has only {{ printf \\\"%.2f\\\" $value }}% available inodes left.\"\n      \"summary\": \"Filesystem has less than 5% inodes left.\"\n    \"expr\": |\n      (\n        node_filesystem_files_free{job=\"node\",fstype!=\"\",mountpoint!=\"\"} / node_filesystem_files{job=\"node\",fstype!=\"\",mountpoint!=\"\"} * 100 < 5\n      and\n        node_filesystem_readonly{job=\"node\",fstype!=\"\",mountpoint!=\"\"} == 0\n      )\n    \"for\": \"1h\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeFilesystemAlmostOutOfFiles\"\n    \"annotations\":\n      \"description\": \"Filesystem on {{ $labels.device }}, mounted on {{ $labels.mountpoint }}, at {{ $labels.instance }} has only {{ printf \\\"%.2f\\\" $value }}% available inodes left.\"\n      \"summary\": \"Filesystem has less than 3% inodes left.\"\n    \"expr\": |\n      (\n        node_filesystem_files_free{job=\"node\",fstype!=\"\",mountpoint!=\"\"} / node_filesystem_files{job=\"node\",fstype!=\"\",mountpoint!=\"\"} * 100 < 3\n      and\n        node_filesystem_readonly{job=\"node\",fstype!=\"\",mountpoint!=\"\"} == 0\n      )\n    \"for\": \"1h\"\n    \"labels\":\n      \"severity\": \"critical\"\n  - \"alert\": \"NodeNetworkReceiveErrs\"\n    \"annotations\":\n      \"description\": \"{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf \\\"%.0f\\\" $value }} receive errors in the last two minutes.\"\n      \"summary\": \"Network interface is reporting many receive errors.\"\n    \"expr\": |\n      rate(node_network_receive_errs_total{job=\"node\"}[2m]) / rate(node_network_receive_packets_total{job=\"node\"}[2m]) > 0.01\n    \"for\": \"1h\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeNetworkTransmitErrs\"\n    \"annotations\":\n      \"description\": \"{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf \\\"%.0f\\\" $value }} transmit errors in the last two minutes.\"\n      \"summary\": \"Network interface is reporting many transmit errors.\"\n    \"expr\": |\n      rate(node_network_transmit_errs_total{job=\"node\"}[2m]) / rate(node_network_transmit_packets_total{job=\"node\"}[2m]) > 0.01\n    \"for\": \"1h\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeHighNumberConntrackEntriesUsed\"\n    \"annotations\":\n      \"description\": \"{{ $labels.instance }} {{ $value | humanizePercentage }} of conntrack entries are used.\"\n      \"summary\": \"Number of conntrack are getting close to the limit.\"\n    \"expr\": |\n      (node_nf_conntrack_entries{job=\"node\"} / node_nf_conntrack_entries_limit) > 0.75\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeTextFileCollectorScrapeError\"\n    \"annotations\":\n      \"description\": \"Node Exporter text file collector on {{ $labels.instance }} failed to scrape.\"\n      \"summary\": \"Node Exporter text file collector failed to scrape.\"\n    \"expr\": |\n      node_textfile_scrape_error{job=\"node\"} == 1\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeClockSkewDetected\"\n    \"annotations\":\n      \"description\": \"Clock at {{ $labels.instance }} is out of sync by more than 0.05s. Ensure NTP is configured correctly on this host.\"\n      \"summary\": \"Clock skew detected.\"\n    \"expr\": |\n      (\n        node_timex_offset_seconds{job=\"node\"} > 0.05\n      and\n        deriv(node_timex_offset_seconds{job=\"node\"}[5m]) >= 0\n      )\n      or\n      (\n        node_timex_offset_seconds{job=\"node\"} < -0.05\n      and\n        deriv(node_timex_offset_seconds{job=\"node\"}[5m]) <= 0\n      )\n    \"for\": \"10m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeClockNotSynchronising\"\n    \"annotations\":\n      \"description\": \"Clock at {{ $labels.instance }} is not synchronising. Ensure NTP is configured on this host.\"\n      \"summary\": \"Clock not synchronising.\"\n    \"expr\": |\n      min_over_time(node_timex_sync_status{job=\"node\"}[5m]) == 0\n      and\n      node_timex_maxerror_seconds{job=\"node\"} >= 16\n    \"for\": \"10m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeRAIDDegraded\"\n    \"annotations\":\n      \"description\": \"RAID array '{{ $labels.device }}' at {{ $labels.instance }} is in degraded state due to one or more disks failures. Number of spare drives is insufficient to fix issue automatically.\"\n      \"summary\": \"RAID Array is degraded.\"\n    \"expr\": |\n      node_md_disks_required{job=\"node\",device!=\"\"} - ignoring (state) (node_md_disks{state=\"active\",job=\"node\",device!=\"\"}) > 0\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"critical\"\n  - \"alert\": \"NodeRAIDDiskFailure\"\n    \"annotations\":\n      \"description\": \"At least one device in RAID array at {{ $labels.instance }} failed. Array '{{ $labels.device }}' needs attention and possibly a disk swap.\"\n      \"summary\": \"Failed device in RAID array.\"\n    \"expr\": |\n      node_md_disks{state=\"failed\",job=\"node\",device!=\"\"} > 0\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeFileDescriptorLimit\"\n    \"annotations\":\n      \"description\": \"File descriptors limit at {{ $labels.instance }} is currently at {{ printf \\\"%.2f\\\" $value }}%.\"\n      \"summary\": \"Kernel is predicted to exhaust file descriptors limit soon.\"\n    \"expr\": |\n      (\n        node_filefd_allocated{job=\"node\"} * 100 / node_filefd_maximum{job=\"node\"} > 70\n      )\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeFileDescriptorLimit\"\n    \"annotations\":\n      \"description\": \"File descriptors limit at {{ $labels.instance }} is currently at {{ printf \\\"%.2f\\\" $value }}%.\"\n      \"summary\": \"Kernel is predicted to exhaust file descriptors limit soon.\"\n    \"expr\": |\n      (\n        node_filefd_allocated{job=\"node\"} * 100 / node_filefd_maximum{job=\"node\"} > 90\n      )\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"critical\"\n  - \"alert\": \"NodeCPUHighUsage\"\n    \"annotations\":\n      \"description\": |\n        CPU usage at {{ $labels.instance }} has been above 90% for the last 15 minutes, is currently at {{ printf \"%.2f\" $value }}%.\n      \"summary\": \"High CPU usage.\"\n    \"expr\": |\n      sum without(mode) (avg without (cpu) (rate(node_cpu_seconds_total{job=\"node\", mode!~\"idle|iowait\"}[2m]))) * 100 > 90\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"info\"\n  - \"alert\": \"NodeSystemSaturation\"\n    \"annotations\":\n      \"description\": |\n        System load per core at {{ $labels.instance }} has been above 2 for the last 15 minutes, is currently at {{ printf \"%.2f\" $value }}.\n        This might indicate this instance resources saturation and can cause it becoming unresponsive.\n      \"summary\": \"System saturated, load per core is very high.\"\n    \"expr\": |\n      node_load1{job=\"node\"}\n      / count without (cpu, mode) (node_cpu_seconds_total{job=\"node\", mode=\"idle\"}) > 2\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeMemoryMajorPagesFaults\"\n    \"annotations\":\n      \"description\": |\n        Memory major pages are occurring at very high rate at {{ $labels.instance }}, 500 major page faults per second for the last 15 minutes, is currently at {{ printf \"%.2f\" $value }}.\n        Please check that there is enough memory available at this instance.\n      \"summary\": \"Memory major page faults are occurring at very high rate.\"\n    \"expr\": |\n      rate(node_vmstat_pgmajfault{job=\"node\"}[5m]) > 500\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeMemoryHighUtilization\"\n    \"annotations\":\n      \"description\": |\n        Memory is filling up at {{ $labels.instance }}, has been above 90% for the last 15 minutes, is currently at {{ printf \"%.2f\" $value }}%.\n      \"summary\": \"Host is running out of memory.\"\n    \"expr\": |\n      100 - (node_memory_MemAvailable_bytes{job=\"node\"} / node_memory_MemTotal_bytes{job=\"node\"} * 100) > 90\n    \"for\": \"15m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeDiskIOSaturation\"\n    \"annotations\":\n      \"description\": |\n        Disk IO queue (aqu-sq) is high on {{ $labels.device }} at {{ $labels.instance }}, has been above 10 for the last 30 minutes, is currently at {{ printf \"%.2f\" $value }}.\n        This symptom might indicate disk saturation.\n      \"summary\": \"Disk IO queue is high.\"\n    \"expr\": |\n      rate(node_disk_io_time_weighted_seconds_total{job=\"node\", device!=\"\"}[5m]) > 10\n    \"for\": \"30m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeSystemdServiceFailed\"\n    \"annotations\":\n      \"description\": \"Systemd service {{ $labels.name }} has entered failed state at {{ $labels.instance }}\"\n      \"summary\": \"Systemd service has entered failed state.\"\n    \"expr\": |\n      node_systemd_unit_state{job=\"node\", state=\"failed\"} == 1\n    \"for\": \"5m\"\n    \"labels\":\n      \"severity\": \"warning\"\n  - \"alert\": \"NodeBondingDegraded\"\n    \"annotations\":\n      \"description\": \"Bonding interface {{ $labels.master }} on {{ $labels.instance }} is in degraded state due to one or more slave failures.\"\n      \"summary\": \"Bonding interface is degraded\"\n    \"expr\": |\n      (node_bonding_slaves - node_bonding_active) != 0\n    \"for\": \"5m\"\n    \"labels\":\n      \"severity\": \"warning\""
  "node.recording.rules.yaml": "\"groups\":\n- \"name\": \"node-exporter.rules\"\n  \"rules\":\n  - \"expr\": |\n      count without (cpu, mode) (\n        node_cpu_seconds_total{job=\"node\",mode=\"idle\"}\n      )\n    \"record\": \"instance:node_num_cpu:sum\"\n  - \"expr\": |\n      1 - avg without (cpu) (\n        sum without (mode) (rate(node_cpu_seconds_total{job=\"node\", mode=~\"idle|iowait|steal\"}[90s]))\n      )\n    \"record\": \"instance:node_cpu_utilisation:rate90s\"\n  - \"expr\": |\n      (\n        node_load1{job=\"node\"}\n      /\n        instance:node_num_cpu:sum{job=\"node\"}\n      )\n    \"record\": \"instance:node_load1_per_cpu:ratio\"\n  - \"expr\": |\n      1 - (\n        (\n          node_memory_MemAvailable_bytes{job=\"node\"}\n          or\n          (\n            node_memory_Buffers_bytes{job=\"node\"}\n            +\n            node_memory_Cached_bytes{job=\"node\"}\n            +\n            node_memory_MemFree_bytes{job=\"node\"}\n            +\n            node_memory_Slab_bytes{job=\"node\"}\n          )\n        )\n      /\n        node_memory_MemTotal_bytes{job=\"node\"}\n      )\n    \"record\": \"instance:node_memory_utilisation:ratio\"\n  - \"expr\": |\n      rate(node_vmstat_pgmajfault{job=\"node\"}[90s])\n    \"record\": \"instance:node_vmstat_pgmajfault:rate90s\"\n  - \"expr\": |\n      rate(node_disk_io_time_seconds_total{job=\"node\", device!=\"\"}[90s])\n    \"record\": \"instance_device:node_disk_io_time_seconds:rate90s\"\n  - \"expr\": |\n      rate(node_disk_io_time_weighted_seconds_total{job=\"node\", device!=\"\"}[90s])\n    \"record\": \"instance_device:node_disk_io_time_weighted_seconds:rate90s\"\n  - \"expr\": |\n      sum without (device) (\n        rate(node_network_receive_bytes_total{job=\"node\", device!=\"lo\"}[90s])\n      )\n    \"record\": \"instance:node_network_receive_bytes_excluding_lo:rate90s\"\n  - \"expr\": |\n      sum without (device) (\n        rate(node_network_transmit_bytes_total{job=\"node\", device!=\"lo\"}[90s])\n      )\n    \"record\": \"instance:node_network_transmit_bytes_excluding_lo:rate90s\"\n  - \"expr\": |\n      sum without (device) (\n        rate(node_network_receive_drop_total{job=\"node\", device!=\"lo\"}[90s])\n      )\n    \"record\": \"instance:node_network_receive_drop_excluding_lo:rate90s\"\n  - \"expr\": |\n      sum without (device) (\n        rate(node_network_transmit_drop_total{job=\"node\", device!=\"lo\"}[90s])\n      )\n    \"record\": \"instance:node_network_transmit_drop_excluding_lo:rate90s\""
  "prometheus.yaml": "\"global\":\n  \"scrape_interval\": \"30s\"\n\"rule_files\":\n- \"/etc/prometheus/*.rules.yaml\"\n\"scrape_configs\":\n- \"bearer_token_file\": \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n  \"job_name\": \"kube-apiserver\"\n  \"kubernetes_sd_configs\":\n  - \"role\": \"endpoints\"\n  \"relabel_configs\":\n  - \"action\": \"keep\"\n    \"regex\": \"default;kubernetes;https\"\n    \"source_labels\":\n    - \"__meta_kubernetes_namespace\"\n    - \"__meta_kubernetes_service_name\"\n    - \"__meta_kubernetes_endpoint_port_name\"\n  \"scheme\": \"https\"\n  \"tls_config\":\n    \"ca_file\": \"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"\n- \"bearer_token_file\": \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n  \"job_name\": \"kubelet\"\n  \"kubernetes_sd_configs\":\n  - \"role\": \"node\"\n  \"relabel_configs\":\n  - \"action\": \"labelmap\"\n    \"regex\": \"__meta_kubernetes_node_label_(.+)\"\n  - \"replacement\": \"kubernetes.default.svc:443\"\n    \"target_label\": \"__address__\"\n  - \"regex\": \"(.+)\"\n    \"replacement\": \"/api/v1/nodes/${1}/proxy/metrics\"\n    \"source_labels\":\n    - \"__meta_kubernetes_node_name\"\n    \"target_label\": \"__metrics_path__\"\n  \"scheme\": \"https\"\n  \"tls_config\":\n    \"ca_file\": \"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"\n- \"bearer_token_file\": \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n  \"job_name\": \"cadvisor\"\n  \"kubernetes_sd_configs\":\n  - \"role\": \"node\"\n  \"metric_relabel_configs\":\n  - \"action\": \"drop\"\n    \"regex\": \"container_([a-z_]+);\"\n    \"source_labels\":\n    - \"__name__\"\n    - \"image\"\n  - \"action\": \"drop\"\n    \"regex\": \"container_(network_tcp_usage_total|network_udp_usage_total|tasks_state|cpu_load_average_10s)\"\n    \"source_labels\":\n    - \"__name__\"\n  \"relabel_configs\":\n  - \"action\": \"labelmap\"\n    \"regex\": \"__meta_kubernetes_node_label_(.+)\"\n  - \"replacement\": \"kubernetes.default.svc:443\"\n    \"target_label\": \"__address__\"\n  - \"regex\": \"(.+)\"\n    \"replacement\": \"/api/v1/nodes/${1}/proxy/metrics/cadvisor\"\n    \"source_labels\":\n    - \"__meta_kubernetes_node_name\"\n    \"target_label\": \"__metrics_path__\"\n  \"scheme\": \"https\"\n  \"tls_config\":\n    \"ca_file\": \"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"\n- \"bearer_token_file\": \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n  \"job_name\": \"kube-state-metrics\"\n  \"kubernetes_sd_configs\":\n  - \"role\": \"pod\"\n  \"relabel_configs\":\n  - \"action\": \"keep\"\n    \"regex\": \"kube-state-metrics\"\n    \"source_labels\":\n    - \"__meta_kubernetes_pod_label_app_kubernetes_io_name\"\n  - \"action\": \"replace\"\n    \"separator\": \":\"\n    \"source_labels\":\n    - \"__meta_kubernetes_pod_name\"\n    - \"__meta_kubernetes_pod_container_port_name\"\n    \"target_label\": \"instance\"\n  \"tls_config\":\n    \"ca_file\": \"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"\n- \"bearer_token_file\": \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n  \"job_name\": \"node\"\n  \"kubernetes_sd_configs\":\n  - \"role\": \"pod\"\n  \"relabel_configs\":\n  - \"action\": \"keep\"\n    \"regex\": \"node-exporter\"\n    \"source_labels\":\n    - \"__meta_kubernetes_pod_label_name\"\n  - \"action\": \"replace\"\n    \"source_labels\":\n    - \"__meta_kubernetes_pod_node_name\"\n    \"target_label\": \"instance\"\n  - \"action\": \"replace\"\n    \"source_labels\":\n    - \"__meta_kubernetes_namespace\"\n    \"target_label\": \"namespace\"\n  - \"replacement\": \"${1}:9100\"\n    \"source_labels\":\n    - \"__address__\"\n    \"target_label\": \"__address__\"\n  \"tls_config\":\n    \"ca_file\": \"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"\n- \"job_name\": \"kubernetes-service-endpoints\"\n  \"kubernetes_sd_configs\":\n  - \"role\": \"endpoints\"\n  \"relabel_configs\":\n  - \"action\": \"keep\"\n    \"regex\": \"true\"\n    \"source_labels\":\n    - \"__meta_kubernetes_service_annotation_prometheus_io_scrape\"\n  - \"action\": \"replace\"\n    \"regex\": \"([^:]+)(?::\\\\d+)?;(\\\\d+)\"\n    \"replacement\": \"$1:$2\"\n    \"source_labels\":\n    - \"__address__\"\n    - \"__meta_kubernetes_service_annotation_prometheus_io_port\"\n    \"target_label\": \"__address__\"\n  - \"action\": \"labelmap\"\n    \"regex\": \"__meta_kubernetes_service_label_(.+)\"\n  - \"action\": \"replace\"\n    \"source_labels\":\n    - \"__meta_kubernetes_namespace\"\n    \"target_label\": \"kubernetes_namespace\"\n  - \"action\": \"replace\"\n    \"source_labels\":\n    - \"__meta_kubernetes_service_name\"\n    \"target_label\": \"kubernetes_name\"\n- \"job_name\": \"kubernetes-services\"\n  \"kubernetes_sd_configs\":\n  - \"role\": \"service\"\n  \"metrics_path\": \"/probe\"\n  \"params\":\n    \"module\":\n    - \"http_2xx\"\n  \"relabel_configs\":\n  - \"source_labels\":\n    - \"__address__\"\n    \"target_label\": \"__param_target\"\n  - \"replacement\": \"blackbox-exporter:9115\"\n    \"target_label\": \"__address__\"\n  - \"source_labels\":\n    - \"__param_target\"\n    \"target_label\": \"instance\"\n  - \"action\": \"labelmap\"\n    \"regex\": \"__meta_kubernetes_service_label_(.+)\"\n  - \"source_labels\":\n    - \"__meta_kubernetes_namespace\"\n    \"target_label\": \"namespace\"\n  - \"source_labels\":\n    - \"__meta_kubernetes_service_name\"\n    \"target_label\": \"name\"\n- \"job_name\": \"kubernetes-ingresses\"\n  \"kubernetes_sd_configs\":\n  - \"role\": \"ingress\"\n  \"metrics_path\": \"/probe\"\n  \"params\":\n    \"module\":\n    - \"http_2xx\"\n  \"relabel_configs\":\n  - \"action\": \"keep\"\n    \"regex\": \"true\"\n    \"source_labels\":\n    - \"__meta_kubernetes_ingress_annotation_prometheus_io_probe\"\n  - \"regex\": \"(.+);(.+);(.+);(.*)\"\n    \"replacement\": \"${1}://${2}${3}${4}\"\n    \"source_labels\":\n    - \"__meta_kubernetes_ingress_scheme\"\n    - \"__address__\"\n    - \"__meta_kubernetes_ingress_path\"\n    - \"__meta_kubernetes_ingress_annotation_prometheus_io_suffix\"\n    \"target_label\": \"__param_target\"\n  - \"replacement\": \"blackbox-exporter:9115\"\n    \"target_label\": \"__address__\"\n  - \"source_labels\":\n    - \"__param_target\"\n    \"target_label\": \"instance\"\n  - \"action\": \"labelmap\"\n    \"regex\": \"__meta_kubernetes_ingress_label_(.+)\"\n  - \"source_labels\":\n    - \"__meta_kubernetes_namespace\"\n    \"target_label\": \"namespace\"\n  - \"source_labels\":\n    - \"__meta_kubernetes_ingress_name\"\n    \"target_label\": \"name\"\n- \"job_name\": \"kubernetes-pods\"\n  \"kubernetes_sd_configs\":\n  - \"role\": \"pod\"\n  \"relabel_configs\":\n  - \"action\": \"keep\"\n    \"regex\": \"true\"\n    \"source_labels\":\n    - \"__meta_kubernetes_pod_annotation_prometheus_io_scrape\"\n  - \"action\": \"labelmap\"\n    \"regex\": \"__meta_kubernetes_pod_label_(.+)\"\n  - \"action\": \"replace\"\n    \"regex\": \"([^:]+)(?::\\\\d+)?;(\\\\d+)\"\n    \"replacement\": \"$1:$2\"\n    \"source_labels\":\n    - \"__address__\"\n    - \"__meta_kubernetes_pod_annotation_prometheus_io_port\"\n    \"target_label\": \"__address__\"\n  - \"action\": \"replace\"\n    \"replacement\": \"$1\"\n    \"separator\": \"/\"\n    \"source_labels\":\n    - \"__meta_kubernetes_namespace\"\n    - \"__meta_kubernetes_pod_label_name\"\n    \"target_label\": \"job\"\n  - \"action\": \"replace\"\n    \"source_labels\":\n    - \"__meta_kubernetes_namespace\"\n    \"target_label\": \"namespace\"\n  - \"action\": \"replace\"\n    \"source_labels\":\n    - \"__meta_kubernetes_pod_name\"\n    \"target_label\": \"instance\"\n  - \"action\": \"labelmap\"\n    \"regex\": \"__meta_kubernetes_pod_annotation_prometheus_io_param_(.+)\"\n    \"replacement\": \"__param_$1\""
"kind": "ConfigMap"
"metadata":
  "name": "prometheus"
  "namespace": "monitoring"